{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Data Science IBM - Capstone Project    \n",
    "   \n",
    "   \n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "### Data source   & use case\n",
    "\n",
    "For this project I am using a dataset from internal source. Data is EEG signals reflecting brain activities. \n",
    "\n",
    "##### What is a EEG signal?      \n",
    "\n",
    "* Based on [wikipedia](https://en.wikipedia.org/wiki/Electroencephalography), Electroencephalography (EEG) is an electrophysiological monitoring method to record electrical activity of the brain. It is typically noninvasive, with the electrodes placed along the scalp, although invasive electrodes are sometimes used, as in electrocorticography. EEG measures voltage fluctuations resulting from ionic current within the neurons of the brain.  \n",
    "\n",
    "And these EEG signals are provided in .h5 format.\n",
    "Labels beloging to datasets are in .txt format and contain int values indicating 4 classes.\n",
    "\n",
    "\n",
    "### Data Integration   \n",
    "\n",
    "#### ETL \n",
    "\n",
    "In this step I prepared few helper fucntions for,   \n",
    "\n",
    "1. reading data \n",
    "2. transorming them to proper shape\n",
    "3. check labels corresponding to signals\n",
    "4. reshape eeg signals to the form of (sample_nr, epochs, channels)\n",
    "5. prepare PCA for dimension reduction \n",
    "\n",
    "I use python language with jupyter notebook. The packages are used in this step are; h5py, matplotlib, sklearn\n",
    "\n",
    "\n",
    "### Discovery and exploration   + Data quality assessment\n",
    "\n",
    "In this steps I check eeg signals to be sure,   \n",
    "\n",
    "1. are they filtered?\n",
    "2. do they need normalization?\n",
    "3. data is balanced or imbalanced?\n",
    "4. if imbalanced, do we need undersampling or over sampling?\n",
    "   \n",
    "   \n",
    "I use python language in jupyter notebook. The packages are used in this step are;  matplotlib (histogram, barplot)\n",
    "\n",
    "\n",
    "\n",
    "### Actionable insights  \n",
    "\n",
    "#### Model definition / Model training\n",
    "\n",
    "\n",
    "For modeling evaluations I used python program with jupyter notebook. Python programming language is one of the most suitable language to do machine learning due to its open source packages and jupyter notebook provides interactive environment to evaluate your analyses. For this project I am using to main approches; 1. Machine learning based modeling, 2. Deep learning based modeling. \n",
    "The Data I am dealing here with has labels so I used supervised learning methods. As a first choice, I used xgboost classifier because of its promissing performance. Then in the next step, I used multiple classifiers from scikit-learn package and I combined classifier comparison step with parameter tunning for each classifier to be able to compare them in their optimal performance. To make learning and comparison even more optimal, I used grid search with 4 fold cross validation and I involved dimesion reduction step in this process using pipeline method from scikit-learning package.   \n",
    "\n",
    "For feature engineering step I applied to different algorithms; 1. I used dimension reduction technique via PCA and, 2. Short Time Fourier Transform (STFT from spicy package) + PCA.   \n",
    "Due to high redundancy in signals it is valid approach to reduce dimensionality of input data. From other side simple time series can have rich information in their frequency domain. To gain information I transfrered them to their frequency domain then removed redundency using PCA again.   \n",
    "\n",
    "In the most of classifiers parallel computation was possible. \n",
    "\n",
    "In second method my aim is to use deep learning approach due to its internal feature engineering capabilities. However deep learning models need a lots of training data which in our case is not possible. For this reason, I used trick called transfer learning to somehow by pass the training problem.   \n",
    "For deep learning base model I use Xception model then, I add 2 dense layer to the top layer of the model. To train and fine tune model I used keras running on NVidia GTX 1080 GPU. \n",
    "\n",
    "The package I used were Tensorflow, Keras\n",
    "\n",
    "\n",
    "\n",
    "#### Model evaluation   \n",
    "\n",
    "since I am dealing with multiclass classification problem I use accuracy metrics to evaluate my models in both machine learning classifiers and deep learning model.\n",
    "\n",
    "\n",
    "\n",
    "### Technological and framework choice   \n",
    "\n",
    "Python programming language with jupyter notebook used in this project.\n",
    "\n",
    "Seaborn and matplotlib is used to visualize the data.\n",
    "For machine learning modeling scikit-learn, spicy, xgboost   \n",
    "For deep learning Tensorflow and keras.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
